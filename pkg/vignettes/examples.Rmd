%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{2. Examples using the poweRlaw package}

```{r echo=FALSE, message=FALSE}
library("knitr")
library("poweRlaw")
options(replace.assign=FALSE)

opts_chunk$set(fig.path='knitr_figure_examples/graphics-', 
               cache.path='knitr_cache_examples/', 
                fig.align='center',
                fig.width=4, fig.height=4, 
                fig.show='hold', cache=FALSE, par=TRUE)

knit_hooks$set(par=function(before, options, envir){
  if (before && options$fig.show!='none') {
    par(mar=c(3,4,2,1),cex.lab=.95,cex.axis=.9,
        mgp=c(3,.7,0),tcl=-.01, las=1)
  }})

set.seed(1)
palette(c(rgb(170,93,152, maxColorValue=255),
          rgb(103,143,57, maxColorValue=255),
          rgb(196,95,46, maxColorValue=255),
          rgb(79,134,165, maxColorValue=255),
          rgb(205,71,103, maxColorValue=255),
          rgb(203,77,202, maxColorValue=255),
          rgb(115,113,206, maxColorValue=255)))
```

```{r echo=FALSE, results='hide', message=FALSE, warning=FALSE, error=FALSE}
if(!file.exists("blackouts.txt")) 
  download.file("http://goo.gl/BsqnP", destfile="blackouts.txt")
```

# Discrete data: Moby Dick

The Moby Dick dataset contains the frequency of unique words in the novel Moby Dick by Herman Melville. This data set can be [downloaded](http://tuvalu.santafe.edu/~aaronc/powerlaws/data.htm) or loaded directly
```{r dis_data}
library("poweRlaw")
data("moby")
```
To fit a discrete power law to this data, we use the `displ` constructor
```{r cache=TRUE}
m_pl = displ$new(moby)
```
The resulting object, `m_pl`, is a `displ` object. It also inherits the `discrete_distribution` class. After creating the `displ object, a typical first step would be to infer model parameters. We can estimate the lower threshold, via
```{r cache=TRUE}
est = estimate_xmin(m_pl)
m_pl$setXmin(est)
```
For a given value $x_{\min}$, the scaling parameter is estimated by numerically optimising the log-likelihood. The optimiser is *initialised* using the analytical MLE
\[
  \hat \alpha \simeq 1 + n \left[\sum_{i=1}^n \log \left(\frac{x_i}{x_{\min} -0.5}\right)\right]^{-1} \;.
\]
This yields a threshold estimate of $x_{\min}=`r est$xmin`$ and scaling parameter $\alpha=`r signif(est$pars, 3)`$, which matches results found in \citet{clauset2009}. 

Alternatively, we could perform a parameter scan for each value of $x_{\min}$
```{r eval=FALSE}
estimate_xmin(m_pl, pars=seq(1.8, 2.3, 0.1))
```
  
To fit a discrete log-normal distribution, we follow a similar procedure, except
we begin by creating a `dislnorm` object

```{r warning=FALSE, eval=FALSE}
m_ln = dislnorm$new(moby)
est = estimate_xmin(m_ln)
```
```{r echo=FALSE}
if(file.exists("examples1.rds")) {
  load("examples1.rds")
} else {
  m_ln = dislnorm$new(moby)
  est = estimate_xmin(m_ln)
  est_ln = est
  est_ln$pars = signif(est_ln$pars, 3)
  m_ln$setXmin(est)
  m_pois = dispois$new(moby)
  est = estimate_xmin(m_pois)
  m_pois$setXmin(est)
  save(m_pois, m_ln, est_ln, file="examples1.rds")
}
```

which yields a lower threshold of $x_{\min}=`r est_ln$xmin`$ and parameters $(`r est_ln$pars[1]`,$ $`r est_ln$pars[2]`)$. A similar procedure is applied to fit the Poisson distribution; we create a distribution object using `dispois`, then fit as before.

The data CDF and lines of best fit (power law (green line), log-normal (red line) and poisson (blue)), can be easily plotted
```{r fig.keep='none', cache=TRUE}
plot(m_pl)
lines(m_pl, col=2)
lines(m_ln, col=3)
lines(m_pois, col=4)
```

```{r echo=FALSE, cache=TRUE, fig.cap="Tes"}
plot(m_pl, xlab="x", ylab="CDF", 
  panel.first=grid(col="grey80"), 
  pch=21, bg=1)

lines(m_pl, col=2, lwd=2)
lines(m_ln, col=3, lwd=2)
lines(m_pois, col=4, lwd=2)
```
It clear that the Poisson distribution is not appropriate for this data set. However, the log-normal and power law distribution both provide reasonable fits to the data.

## Parameter uncertainty

```{r par_uncertainty, echo=FALSE}
data(bootstrap_moby)
bs = bootstrap_moby
```
  To get a handle on the uncertainty in the parameter estimates, we use a
bootstrapping procedure, via the *bootstrap* function. This procedure can
be applied to any distribution object. Furthermore, the bootstrap procedure can utilize
multiple CPU cores to speed up inference.\
```{r eval=FALSE, tidy=FALSE}
## 5000 bootstraps using two cores
## Stored in data(bootstrap_moby)
bs = bootstrap(m_pl, no_of_sims=5000, threads=2)
```
By default, the `bootstrap` function will use the maximum likelihood estimate to estimate the parameter and check all values of $x_{\min}$. When possible $x_{\min}$ values are large, then it is recommend that the search space is reduced. For example, this function call
```{r eval=FALSE}
bootstrap(m_pl, xmins = seq(2, 20, 2))
```
will only calculate the Kolmogorov-Smirnoff statistics at values of $x_{\min}$ equal to
\[
2, 4, 6, \ldots, 20\;.
\]
A similar argument exists for the parameters.

The bootstrap function, returns `bs_xmin` object that has three components:

  * The goodness of fit statistic obtained from the Kolmogorov-Smirnoff test. This value should correspond to the value obtained from the `estimate\_xmin` function.
  * A data frame containing the results for the bootstrap procedure. 
  * The average simulation time, in seconds, for a single bootstrap.

The boostrap results can be explored in a variety way. First we can estimate the standard deviation of the parameter uncertainty, i.e.

```{r echo=FALSE, fig.width=8, fig.height=8}
plot(bs)
```

The top row shows the mean estimate of parameters $x_{\min}$ and $\alpha$. The bottom row shows the estimate of standard deviation for each parameter. The dashed-lines give approximate 95\% confidence intervals. After 5,000 iterations, the standard deviation of $x_{\min}$ and $\alpha$ is estimated to be 2.1 and 0.03 respectively.

```{r }
sd(bs$bootstraps[,2])
sd(bs$bootstraps[,3])
```
Alternatively, we can visualise the results using the \cc{plot} function:
```{r fig.keep='none'}
## trim=0.1 only displays the final 90% of iterations 
plot(bs, trim=0.1)
```
The top row of graphics give a 95\% confidence interval for the mean estimate of the parameters. The bottom row of graphics give a 95\% confidence for the standard deviation of the parameters. The parameter `trim` in the `plot` function controls the percentage of samples displayed. When `trim=0.1`, we only display the final 90\% of data. 

```{r echo=FALSE, fig.width=6, fig.height=3, cache=TRUE}
par(mfrow=c(1, 2))
hist(bs$bootstraps[,2], xlab=expression(x[min]), ylim=c(0, 1600), 
     xlim=c(0, 20), main=NULL, breaks="fd")
grid()
hist(bs$bootstraps[,3], xlab=expression(alpha), 
     ylim=c(0, 500), xlim=c(1.80, 2.05), main=NULL, breaks="fd")
grid()
```
  \caption{Characterising uncertainty in parameter values. (a) $x_{\min}$ uncertainty (standard deviation 2) (b) $\alpha$ uncertainty (std dev. 0.03)}\label{F1c}
\end{figure}

We can also construct histograms. 
```{r fig.keep='none'}
hist(bs$bootstraps[,2])
hist(bs$bootstraps[,3]) 
```
to get figure \ref{F1c}. 

A similar bootstrap analysis can be obtained for the log-normal distribution
```{r eval=FALSE}
bs1 = bootstrap(m_ln)
```
in this case we would obtain uncertainty estimates for both of the log-normal parameters.

```{r echo=FALSE}
data(bootstrap_p_moby)
bs_p = bootstrap_p_moby
```

```{r echo=FALSE, fig.width=6, fig.height=4, cache=TRUE, out.width='\\textwidth'}
plot(bs_p)
```
  \caption{Results from the bootstrap procedure (for the power law model) using the Moby Dick data set: \mbox{\texttt{bootstrap\_p(m\_pl)}}. The top row shows the mean estimate of parameters $x_{\min}$,  $\alpha$ and the $p\,$-value. The bottom row shows the estimate of standard deviation for each parameter. The dashed-lines give approximate 95\% confidence intervals.}\label{F1d}
\end{figure}

## Testing the power law hypothesis

Since it is possible to fit a power law distribution to *any* data set, it is appropriate to test whether the observed data set actually follows a power law. \citet{clauset2009} suggest that this hypothesis is tested using a goodness-of-fit test, via a bootstrapping procedure. This test generates a $p\,$-value that can be used to quantify the plausibility of the hypothesis. If the $p\,$-value is large, than any difference between the empirical data and the model can be explained with statistical fluctuations. If $p \simeq 0$, then the model does not provide a plausible fit to the data and another distribution may be more appropriate. In this scenario, 
\begin{align*}
&H_0: \mbox{data is generated from a power law distribution.}\\
&H_1: \mbox{data is not generated from a power law distribution.}
\end{align*}
To test these hypothesis, we use the `bootstrap_p` function
```{r testing_pl, eval=FALSE}
bs_p = bootstrap_p(m_pl)
```
The point estimate of the $p\,$-value is one of the elements of the
`bs_p` object
```{r}
bs_p$p
```
Alternatively we can plot the results
```{r fig.keep='none', cache=TRUE}
plot(bs_p)
```
to obtain figure \ref{F1d}. The graph in the top right hand corner
gives the cumulative estimate of the $p\,$-value; the final value of the purple
line corresponds to `bs\_p\$p`. Also given are approximate 95\%
confidence intervals.

## Comparing distributions

A second approach to test the power law hypothesis is a direct comparison of two
models. A standard technique is to
use Vuong's test, which a likelihood ratio test for model selection using the
Kullback-Leibler criteria. The test statistic, $R$, is the ratio of the
log-likelihoods of the data between the two competing models. The sign of $R$
indicates which model is *better*. Since the value of $R$ is obviously
subject to error, we use the method proposed by \cite{Vuong1989}.

To compare two distributions, each distribution must have the same lower
threshold. So we first set the log normal distribution object to have the same
$x_{\min}$ as the power law object
```{r comp_dist, cache=TRUE}
m_ln$setXmin(m_pl$getXmin())
```
Next we estimate the parameters for this particular value of $x_{\min}$:
```{r cache=TRUE}
est = estimate_pars(m_ln)
m_ln$setPars(est)
```
Then we can compare distributions
```{r cache=TRUE}
comp = compare_distributions(m_pl, m_ln)
```
This comparison gives a $p$-value of `r signif(comp[["p_two_sided"]], 4)`.
This $p\,$-value corresponds to the $p$-value on page 29 of the
\citeauthor{clauset2009} paper (the paper gives 0.69).

Overall these results suggest that one model can't be favoured over the other. 

## Investigating the lower bound

The estimate of the scaling parameter, $\alpha$, is typically highly correlated
with the threshold limit, $x_{\min}$. This relationship can be easily investigated
with the `poweRlaw` package. First, we create a vector of thresholds to scan
```{r }
xmins = seq(1, 1001, 5)
```

```{r est_scan, echo=FALSE, cache=TRUE}
est_scan = 0*xmins
for(i in seq_along(xmins)){
  m_pl$setXmin(xmins[i])
  est_scan[i] = estimate_pars(m_pl)$pars
}
```
  
```{r echo=FALSE, cache=TRUE}
plot(xmins, est_scan, type="s", 
  panel.first=grid(), 
  xlab=expression(x[min]), ylab=expression(alpha), 
  ylim=c(1.6, 2.8), col=1)
abline(h=1.95, col=2, lty=2)
```
  \caption{Estimated parameter values conditional on the threshold, $x_{\min}$. The
           horizontal line corresponds to $\alpha=1.95$.}\label{F1e}

then a vector to store the results
```{r est_scan, echo=1, eval=FALSE}
```
Next, we loop over the $x_{\min}$ values and estimate the parameter value
conditional on the $x_{\min}$ value
```{r est_scan, echo=2:4, eval=FALSE}
```
The results are plotted figure \ref{F1e}. For this data set, as the
lower threshold increases, so does the point estimate of $\alpha$.


# Continuous data: electrical blackouts

In this example, we will investigate the numbers of customers affected in
electrical blackouts in the United States between 1984 and 2002 (see
                                                                 \cite{newman2005} for further details). The data set can be downloaded from
Clauset's [website](http://tuvalu.santafe.edu/~aaronc/powerlaws/data/blackouts.txt) and loaded into R in the usual way
```{r}
blackouts = read.table("blackouts.txt")
```
Although the `blackouts` data set is discrete, since the values are large it makes sense to treat the data as continuous. Continuous power law objects take vectors as inputs, so
```{r cache=TRUE}
m_bl = conpl$new(blackouts$V1)
```
then we estimate the lower-bound via
```{r cache=TRUE}
est = estimate_xmin(m_bl)
```
This gives a point estimate of $x_{\min}=`r est$xmin`$. We can then update the distribution object
```{r cache=TRUE}
m_bl$setXmin(est)
```
and plot the data with line of best fit
```{r fig.keep='none', cache=TRUE}
plot(m_bl)
lines(m_bl, col=2, lwd=2)
```
to get figure \ref{F2a}. To fit a discrete log-normal distribution we follow a similar procedure
```{r m_bl_ln, echo=FALSE, cache=TRUE}
m_bl_ln = conlnorm$new(blackouts$V1)
est = estimate_xmin(m_bl_ln)
m_bl_ln$setXmin(est)
```

```{r echo=FALSE, fig.width=4, fig.height=4}
plot(m_bl, pch=21, bg=1, 
panel.first=grid(col="grey80"), 
xlab="Blackouts", ylab="CDF")
lines(m_bl, col=2, lwd=3)
lines(m_bl_ln, col=3, lwd=3)
```

\caption{CDF plot of the blackout dataset with line of best fit. Since the minimum value of $x$ is large, we fit a continuous power law as this is more it efficient. The power law fit is the green line, the discrete log-normal is the red line.}\label{F2a}
\end{figure}
```{r m_bl_ln, eval=FALSE}
```
and add the line of best fit to the plot via
```{r eval=FALSE}
lines(m_bl_ln, col=3, lwd=2)
```
It is clear from figure \ref{F2a} that the log-normal distribution provides a better fit to this data set.


# Multiple data sets: the American-Indian war

In a recent paper, \citeauthor{Bohorquez2009} investigated insurgent attacks in
Afghanistan, Iraq, Colombia, and Peru. Each time, the data resembled power laws.
\citeauthor{Friedman2013} used the power law nature of casualties to infer
under-reporting in the American-Indian war. Briefly, by fitting a power law
distribution to the observed process, the latent, unobserved casualties can be
inferred (\cite{Friedman2013}).

The number of casualties observed in the American-Indian War can be obtained via
```{r }
data("native_american")
data("us_american")
```
Each data set is a data frame with two columns. The first column is number of casualties recorded, the second the conflict date
```{r }
head(native_american, 3)
```
The records span around one hundred years, 1776 -- 1890. The data is plotted in figure \ref{F3a}. 

```{r echo=FALSE, fig.width=6, fig.height=4, out.width="0.8\\textwidth"}
plot(native_american$Date, native_american$Cas, 
log="y", pch=21, bg=1, 
ylim=c(1, 2000), 
cex=0.5, panel.first=grid(col="grey70"), 
xlab="Date", ylab="#Casualties")
points(us_american$Date, us_american$Cas, 
pch=24, bg=2, cex=0.5)
```
\caption{Casualty record for the Indian-American war, 1776 -- 1890. Native
Americans casualties (purple circles) and US Americans casualties (green
triangles). Data taken from \citet{Friedman2013}.}\label{F3a}

It is straightforward to fit a discrete power law to this data set. First, we
create discrete power law objects
```{r cache=TRUE}
m_na = displ$new(native_american$Cas)
m_us = displ$new(us_american$Cas)
```
then we estimate $x_{\min}$ for each data set
```{r cache=TRUE}
est_na = estimate_xmin(m_na, pars=seq(1.5, 2.5, 0.01))
est_us = estimate_xmin(m_us, pars=seq(1.5, 2.5, 0.01))
```
and update the power law objects
```{r cache=TRUE}
m_na$setXmin(est_na)
m_us$setXmin(est_us)
```
The resulting fitted distributions can be plotted on the same figure
```{r fig.keep='none', cache=TRUE, tidy=FALSE}
plot(m_na)
lines(m_na)
## Don't create a new plot, just store the output
d = plot(m_us, draw=FALSE)
points(d$x, d$y, col=2)
lines(m_us, col=2)
```

```{r echo=FALSE}
plot(m_na, bg=1, pch=21, cex=0.5,  
  panel.first=grid(col="grey70"), 
  xlab="#Casualties", ylab="CDF")
lines(m_na, lwd=2, col=1)

d = plot(m_us, draw=FALSE)
points(d$x, d$y, bg=2, pch=24, cex=0.5)
lines(m_us, lwd=2, col=2)
```
\caption{Plots of the CDFs for the Native American and US American casualties.
           The lines of best fit are also given.}\label{F3b}

The result is given in figure \ref{F3b}. The tails of the
distributions appear to follow a power law. This is consistent with the
expectation that smaller-scale engagements are less likely to be recorded.
However, for larger scale engagements, it is very likely that a record is made.

```{r clean-up, include=FALSE}
# R compiles all vignettes in the same session, which can be bad
rm(list = ls(all = TRUE))
```
  
\bibliography{poweRlaw}
\bibliographystyle{plainnat}



